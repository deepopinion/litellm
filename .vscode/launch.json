{
    "configurations": [
        {
            "name": "LiteLLM Fake OpenAI Endpoint",
            "type": "debugpy",
            "request": "launch",
            "python": "${command:python.interpreterPath}", // select the python interpreter in vscode fist 
            "program": "${workspaceFolder}/litellm/proxy/proxy_load_test/openai_endpoint.py",
            "console": "integratedTerminal"
        },
        {
            "name": "LiteLLM Proxy Debug", 
            "type": "debugpy",
            "request": "launch",
            "python": "${command:python.interpreterPath}", // select the python interpreter in vscode fist 
            "program": "${workspaceFolder}/litellm/proxy/proxy_cli.py",
            "args": [
                "--config",
                "${workspaceFolder}/config.dev.yml",
            ],
            "console": "integratedTerminal"
        }
    ]
}